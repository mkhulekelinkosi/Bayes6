---
title: "Assignment6_bayes"
author: "mkhulekeli Nkosi 2017159092"
date: "2025-05-18"
output: word_document
---
```{r}
#(timestamp <- format(Sys.time(), "%Y-%m-%d_%H-%M")
#dir.create(paste0("backups/auto_backup_", timestamp))
#file.copy("scripts/", paste0("backups/auto_backup_", timestamp), recursive = TRUE))
if (!dir.exists("backups1")) {
  dir.create("backups1")
}
backup_dir <- file.path("backups1", paste0("auto_backup_1", timestamp))
dir.create(backup_dir)
file.copy("scripts/", backup_dir, recursive = TRUE)
message("âœ… Backup completed.")

```

# 1. 

The residual error is caused by the different  groups that will do presentation and by the different groups of assessors. Also not having enough variables to explain the the final mark.

# 2. 

There is always a factor that influences an outcome but according to the above assumptions i would say in this case they are enough for the average assessor mark to be correct on average.

# 3. 

```{r}
data<- readxl::read_xlsx("BayesAssignment6of2025.xlsx")
summary(data)
sapply(data, class)

colSums(is.na(data))
library(mice)
md.pattern(data)

```

All the columns are numeric excerpt for the group column. And 45 missing values are observed in total. The missingness patterns given the visualisations on can conclude that the middingness is MAR because the missin values in lecturer E are missing when lecture F And G are missing missingness is dependent on the two variables also lecture D only one is not dependent on G and F.

# 4. 

```{r}
library(tidyr)

long_data <- pivot_longer(data, cols= c(LecturerA,LecturerB,LecturerC,LecturerD,LecturerE,LecturerF,LecturerG) ,names_to = c("Lecturer"), values_to = "Score")

new_data<- na.omit(long_data)
unique(new_data$Lecturer)
```

# 5. 

In our case the group of students is our Fixed effect because we not interested in how the next possible group will affect the final mark, with the lecturer as the random effect each group will experience the lecture effect and one would like to know how a different lecturer not included in this fit  will grade each group.(read slides)

# 6.

```{r}
library(brms)
model <- brm(
  formula = Score ~ Group  + (1 | Lecturer),
  data = new_data,
  iter = 5000
)
summary(model)
est<- posterior_samples(model)
pred<- posterior_predict(model)
ranef(model)
fixed_effects <- fixef(model, summary = TRUE) 
pred<- posterior_epred(model)
fit<-fitted(model)
pred_vals <- predict(model, summary = TRUE)
data<- cbind(new_data$Group,fit,pred_vals)
data<- data[,-6]
```
# 7.

```{r}

```

# 8. 

# 9.

```{r}
library(tidyr)
library(dplyr)

long_data_mark<- new_data %>%
  pivot_longer(cols = c(Proposal, Quiz,Literature,Interview),
               names_to = "mark_type",
               values_to = "mark")
library(ggplot2)

ggplot(long_data_mark, aes(x = mark, color = mark_type)) +
  geom_density(size = 1.5) +
  labs(title = "Density of Multiple Continuous Variables",
       x = "Score",
       y = "Density",
       color = "Variable") +
    xlim(25, 125) +
  theme_minimal()



hist(long_data_mark$mark/100)
mean(long_data_mark$mark)
sd(long_data_mark$mark)

alpha =14
beta = 6

  
model2 <- brm(
  formula = (Score/100) ~ Group  + (1 | Lecturer),
  data = new_data,
  family = Beta(),
  iter = 5000
)

```

Using the histogram and given that the values are bounded between 0 and 100 it makes a beta distribution with alpha less than  beta is chosen as our prior. And Given that the average mark is 70 one can use a total strength that is between 10 and 30 to have a moderate prior in our case 20 was chosen.(OpenAI. ChatGPT. May 23 version, 2025, https://chat.openai.com/.)



